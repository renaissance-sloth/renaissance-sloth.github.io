---
title: "12장 AFTERWORD"
excerpt: "양자역학 추가 단원"
tags: [quantum mechanics]
header:
  teaser: https://drive.google.com/thumbnail?id=1Qm_zarRZ2x-0ElOGprphzt1zN4FiPnS6&sz=w1000
---

## CHAPTER 12 

### AFTERWORD 

Now that you have (I hope) a **sound understanding of what quantum mechanics** says, I would like to return to the question of **what it means**—continuing the story begun in Section 1.2.

The source of the problem is the **indeterminacy** associated with the **statistical interpretation** of the wave function. For $\Psi$ (or, more generally, the **quantum state**—it could be a spinor, for example) does not uniquely determine the outcome of a measurement ; all it provides is the **statistical distribution** of possible results. This raises a profound question: Did the physical system "**actually have**" the attribute in question prior to the measurement (the so-called **realist viewpoint**), or did the act of measurement itself "**create**" the property, limited only by the statistical constraint imposed by the wave function (the **orthodox position**)—or can we duck the question entirely, on the grounds that it is "**metaphysical**" (the **agnostic response**)? 

According to the realist, quantum mechanics is an **incomplete theory**, for even if you know everything quantum mechanics has to tell you about the system (to wit: its wave function), still you cannot determine all of its features. Evidently there is some other information, **external to quantum mechanics**, which (together with $\Psi$) is required for a complete description of physical reality.

The orthodox position raises even more disturbing problems, for if the act of measurement forces the system to "**take a stand**," helping to create an attribute that was not there previously, then there is something very peculiar about the 

> **Note:** This may be strange, but it is not mystical, as some popularizers would like to suggest. The so-called wave-particle duality, which Niels Bohr elevated to the status of a cosmic principle (complementarity), makes electrons sound like unpredictable adolescents, who sometimes behave like 

420

---

$\pi^{0}$ 

### Section 12.1: The EPR Paradox 

421 

 

...measurement process. Moreover, in order to account for the fact that an immediately repeated measurement yields the same result, we are forced to assume that the act of measurement **collapses the wave function**, in a manner that is difficult, at best, to reconcile with the normal evolution prescribed by the **Schrödinger equation**.

In light of this, it is no wonder that generations of physicists retreated to the **agnostic position**, and advised their students not to waste time worrying about the conceptual foundations of the theory.

## 12.1 THE EPR PARADOX 

In 1935, Einstein, Podolsky, and Rosen$^2$ published the famous **EPR paradox**, which was designed to prove (on purely theoretical grounds) that the **realist position** is the only sustainable one. I'll describe a simplified version of the EPR paradox, introduced by **David Bohm**.

Consider the decay of the neutral pi meson ($\pi^0$) into an electron ($e^-$) and a positron ($e^+$):
$$\pi^{0}\rightarrow e^{-}+e^{+}$$ 

Assuming the pion was at rest, the electron and positron fly off in **opposite directions** (Figure 12.1). Now, the pion has **spin zero**, so **conservation of angular momentum** requires that the electron and positron are in the **singlet configuration**:
$$\frac{l}{\sqrt{2}}(\chi_{-}\psi_{+}-\chi_{-}\psi_{+}).$$ 
If the electron is found to have **spin up**, the positron must have **spin down**, and vice versa. Quantum mechanics can't tell you which combination you'll get, in any particular pion decay, but it does say that the measurements will be **correlated**, and you'll get each combination half the time (on average).

Now suppose 

> **Note:** ...adults, and sometimes, for no particular reason, like children. I prefer to avoid such language. When I say that a particle does not have a particular attribute before its measurement, I have in mind for example, an electron in the spin state $\chi=\begin{pmatrix}1\\ 0\end{pmatrix}$: a measurement of the x-component of its angular momentum could return the value $\hbar/2$, or (with equal probability) the value $-\hbar/2$, but until the measurement is made it simply does not have a well-defined value of $S_{x}$. 

$^2$A. Einstein, B. Podolsky, and N. Rosen, Phys. Rev. 47, 777 (1935).

---

422 

Chapter 12 Afterword 

...we let the electron and positron fly way off—10 meters, in a practical experiment, or, in principle, 10 light years—and then you measure the spin of the electron. Say you get **spin up**. Immediately you know that someone 20 meters (or 20 light years) away will get **spin down**, if that person examines the positron.

To the **realist**, there's nothing surprising in this: the electron **really had spin up** (and the positron spin down) from the moment they were created—it's just that quantum mechanics didn't know about it. But the "**orthodox**" view holds that **neither particle had either spin up or spin down until the act of measurement intervened**: Your measurement of the electron **collapsed the wave function**, and instantaneously "**produced**" the spin of the positron 20 meters (or 20 light years) away.

Einstein, Podolsky, and Rosen considered such "**spooky action-at-a-distance**" (Einstein's words) preposterous. They concluded that the **orthodox position is untenable**; the electron and positron must have had well-defined spins all along, whether quantum mechanics can calculate them or not.

The fundamental assumption on which the EPR argument rests is that **no influence can propagate faster than the speed of light**. We call this the **principle of locality**. You might be tempted to propose that the collapse of the wave function is not instantaneous, but "travels" at some finite velocity. However, this would lead to **violations of angular momentum conservation**, for if we measured the spin of the positron before the news of the collapse had reached it, there would be a fifty-fifty probability of finding both particles with spin up. Whatever one might think of such a theory in the abstract, the experiments are unequivocal: **No such violation occurs**—the (anti-)correlation of the spins is **perfect**. Evidently the collapse of the wave function—whatever its ontological status—is **instantaneous**.

**Problem 12.1 Entangled states.** The singlet spin configuration (Equation 12.1) is the classic example of an **entangled state**—a two-particle state that cannot be expressed as the product of two one-particle states, and for which, therefore, one cannot really speak of "the state" of either particle separately. You might wonder whether this is somehow an artifact of bad notation—maybe some linear combination of the one-particle states would disentangle the system.

**Prove the following theorem:** 

Consider a two-level system, $|\phi_{a}\rangle$ and $|\phi_{b}\rangle$, with $\langle\phi_{i}|\phi_{j}\rangle=\delta_{ij}$. (For example, $|\phi_{a}\rangle$ might represent spin up and $|\phi_{b}\rangle$ spin down.) The two-particle state:
$$\alpha|\phi_{a}(1)\rangle|\phi_{b}(2)\rangle+\beta|\phi_{b}(1)\rangle|\phi_{a}(2)\rangle$$ 

---

Section 12.2: Bell's Theorem 

423 

(with $\alpha\ne0$ and $\beta\ne0$) cannot be expressed as a product 
$$|\psi_{r}(1)\rangle|\psi_{s}(2)\rangle$$ 
for any one-particle states $|\psi_{r}\rangle$ and $|\psi_{s}\rangle$.

> **Hint:** Write $|\psi_{r}\rangle$ and $|\psi_{s}\rangle$ as linear combinations of $|\phi_{a}\rangle$ and $|\phi_{b}\rangle$.

## 12.2 BELL'S THEOREM 

Einstein, Podolsky, and Rosen did not doubt that quantum mechanics is correct, as far as it goes ; they only claimed that it is an **incomplete description of physical reality**: The wave function is not the whole story—some other quantity, $\lambda$, is needed, in addition to $\Psi$, to characterize the state of a system fully. We call $\lambda$ the "**hidden variable**" because, at this stage, we have no idea how to calculate or measure it.$^3$  Over the years, a number of **hidden variable theories** have been proposed, to supplement quantum mechanics; they tend to be cumbersome and implausible, but never mind—until 1964 the program seemed eminently worth pursuing. But in that year **J. S. Bell proved that any local hidden variable theory is incompatible with quantum mechanics**.$^5$ 

Bell suggested a **generalization of the EPR/Bohm experiment**: Instead of orienting the electron and positron detectors along the same direction, he allowed them to be rotated independently. The first measures the component of the electron spin in the direction of a unit vector **a**, and the second measures the spin of the positron along the direction **b** (Figure 12.2). For simplicity, let's record the spins in units of $\hbar/2$ ; then each detector registers the value **+1** (for spin up) or **-1** (spin down), along the direction in question.

A table of results, for many $\pi^{0}$ decays, might look like this:

| electron | positron | product |
| :---: | :---: | :---: |
| +1  | -1  | -1  |
| +1  | -1  | -1  |
| -1  | +1  | -1  |
| +1  | +1  | +1  |
| -1  | -1  | +1  |
| -1  | -1  | +1  |
| -1  | +1  | -1  |
| +1  | -1  | -1  |

$^3$ The hidden variable could be a single number, or it could be a whole collection of numbers: perhaps $\lambda$ is to be calculated in some future theory , or maybe it is for some reason of principle incalculable. It hardly matters. All I am asserting is that there must be something—if only a list of the outcomes of every possible experiment—associated with the system prior to a measurement.

$^4$ D. Bohm, Phys. Rev. 85, 166, 180 (1952).

$^5$ Bell's original paper (Physics 1, 195 (1964)) is a gem: brief, accessible, and beautifully written.

---

 

424 

Chapter 12 Afterword 

Bell proposed to calculate the **average value of the product of the spins**, for a given set of detector orientations. Call this average $P(\mathbf{a},\mathbf{b})$. If the detectors are **parallel** ($\mathbf{b}=\mathbf{a}$), we recover the original EPRB configuration ; in this case one is spin up and the other spin down, so the product is always $-1$, and hence so too is the average:
$$P(\mathbf{a},\mathbf{a})=-1.$$ 
By the same token, if they are **anti-parallel** ($\mathbf{b}=-\mathbf{a}$), then every product is $+1$, so:
$$P(\mathbf{a},-\mathbf{a})=+1.$$ 

For **arbitrary orientations**, quantum mechanics predicts:
$$P(\mathbf{a},\mathbf{b})=-\mathbf{a}\cdot \mathbf{b}$$ 
(see Problem 4.50) . What Bell discovered is that this result is **incompatible with any local hidden variable theory**.

The argument is stunningly simple. Suppose that the "complete" state of the electron/positron system is characterized by the hidden variable(s) $\lambda$ ($\lambda$ varies, in some way that we neither understand nor control, from one pion decay to the next). Suppose further that the outcome of the electron measurement is **independent of the orientation ($\mathbf{b}$) of the positron detector**—which may, after all, be chosen by the experimenter at the positron end just before the electron measurement is made, and hence far too late for any subluminal message to get back to the electron detector. (This is the **locality assumption**) . Then there exists some function $A(\mathbf{a},\lambda)$ which gives the result of an electron measurement, and some other function $B(\mathbf{b},\lambda)$ for the positron measurement. These functions can only take on the values $\pm 1$:$^6$ 
$$A(\mathbf{a},\lambda)=\pm1; B(\mathbf{b},\lambda)=\pm1.$$ 

$^6$ This already concedes far more than a classical determinist would be prepared to allow, for it abandons any notion that the particles could have well-defined angular momentum vectors with simultaneously determinate components. But never mind—the point of Bell's argument is to demonstrate that quantum mechanics is incompatible with any local deterministic theory—even one that bends over backwards to be accommodating.

---

Section 12.2: Bell's Theorem 

425 

When the detectors are aligned, the results are perfectly (anti)-correlated:
$$A(\mathbf{a},\lambda)=-B(\mathbf{a},\lambda)$$ 
for all $\lambda$.

Now, the average of the product of the measurements is:
$$P(\mathbf{a},\mathbf{b})=\int\rho(\lambda)A(\mathbf{a},\lambda)B(\mathbf{b},\lambda)d\lambda.$$ 

where $\rho(\lambda)$ is the **probability density for the hidden variable**. (Like any probability density, it is nonnegative, and satisfies the normalization condition $\int\rho(\lambda)d\lambda=1$, but beyond this we make no assumptions about $\rho(\lambda)$—different hidden variable theories would presumably deliver quite different expressions for $\rho$). In view of Equation 12.6, we can eliminate $B$:
$$P(\mathbf{a},\mathbf{b})=-\int\rho(\lambda)A(\mathbf{a},\lambda)A(\mathbf{b},\lambda)d\lambda,$$ 

If $\mathbf{c}$ is any other unit vector,
$$P(\mathbf{a},\mathbf{b})-P(\mathbf{a},\mathbf{c})=-\int\rho(\lambda)[A(\mathbf{a},\lambda)A(\mathbf{b},\lambda)-A(\mathbf{a},\lambda)A(\mathbf{c},\lambda)]d\lambda.$$ 

Or, since $[A(\mathbf{b},\lambda)]^{2}=1$:
$$P(\mathbf{a},\mathbf{b})-P(\mathbf{a},\mathbf{c})=-\int\rho(\lambda)[1-A(\mathbf{b},\lambda)A(\mathbf{c},\lambda)]A(\mathbf{a},\lambda)A(\mathbf{b},\lambda)d\lambda.$$ 

But it follows from Equation 12.5 that $-1\le[A(\mathbf{a},\lambda)A(\mathbf{b},\lambda)]\le+1$; moreover $\rho(\lambda)[1-A(\mathbf{b},\lambda)A(\mathbf{c},\lambda)]\ge0$ so:
$$|P(\mathbf{a},\mathbf{b})-P(\mathbf{a},\mathbf{c})|\le\int\rho(\lambda)[1-A(\mathbf{b},\lambda)A(\mathbf{c},\lambda)]d\lambda.$$ 

or, more simply:
$$|P(\mathbf{a},\mathbf{b})-P(\mathbf{a},\mathbf{c})|\le1+P(\mathbf{b},\mathbf{c}).$$ 

This is the famous **Bell inequality**. It holds for any **local hidden variable theory** (subject only to the minimal requirements of Equations 12.5 and 12.6), for we have made no assumptions whatever as to the nature or number of the hidden variable(s), or their distribution ($\rho$).

But it is easy to show that the quantum mechanical prediction (Equation 12.4) is **incompatible with Bell's inequality**. For example, suppose all three vectors lie in 

---

 

426 

Chapter 12 Afterword 

...a plane, and **c** makes a $45^{\circ}$ angle with **a** and **b** (Figure 12.3); in this case quantum mechanics says:
$$P(\mathbf{a},\mathbf{b})=0$$ 
$$P(\mathbf{a},\mathbf{c})=P(\mathbf{b},\mathbf{c})=-\cos(45^\circ) \approx -0.707.$$ 

which is patently inconsistent with Bell's inequality:
$$|0 - (-0.707)| \le 1 + (-0.707)$$
$$0.707 \le 0.293$$ 

With Bell's modification, then, the EPR paradox proves something far more radical than its authors imagined: If they are right, then not only is quantum mechanics incomplete, it is **downright wrong**. On the other hand, if quantum mechanics is right, then **no hidden variable theory is going to rescue us from the nonlocality** Einstein considered so preposterous. Moreover, we are provided with a very simple experiment to settle the issue once and for all.

Many experiments to test Bell's inequality were performed in the '60's and '70's, culminating in the work of **Aspect, Grangier, and Roger**.$^7$  The details do not concern us here (they actually used two-photon atomic transitions, not pion decays). To exclude the remote possibility that the positron detector might somehow "sense" the orientation of the electron detector, both orientations were set quasi-randomly **after the photons were already in flight**. The results were in **excellent agreement with the predictions of quantum mechanics**, and **clearly incompatible with Bell's inequality**.$^8$ 

Ironically, the experimental confirmation of quantum mechanics came as something of a **shock** to the scientific community. But not because it spelled the demise of "**realism**"—most physicists had long since adjusted to this (and for those who could not, there remained the possibility of **nonlocal hidden variable theories**, 

$^7$ A. Aspect, P. Grangier, and G. Roger, Phys. Rev. Lett. 49, 91 (1982). For more recent experiments see G. Weihs et al., Phys. Rev. Lett. 81, 5039 (1998).

$^8$ Bell's theorem involves averages and it is conceivable that an apparatus such as Aspect's contains some secret bias which selects out a nonrepresentative sample, thus distorting the average. In 1989, an improved version of Bell's theorem was proposed, in which a single measurement suffices to distinguish between the quantum prediction and that of any local hidden variable theory. See D. Greenberger, M. Horne, A. Shimony, and A. Zeilinger, Am. J. Phys. 58, 1131 (1990) and N. David Mermin, Am. J. Phys. 58, 731 (1990).

---

 

Section 12.2: Bell's Theorem 427 

...to which Bell's theorem does not apply). The real shock was the demonstration that **nature itself is fundamentally nonlocal**. **Nonlocality**, in the form of the instantaneous collapse of the wave function (and for that matter also in the symmetrization requirement for identical particles) had always been a feature of the orthodox interpretation, but before Aspect's experiment it was possible to hope that quantum nonlocality was somehow a nonphysical artifact of the formalism, with no detectable consequences. That hope can no longer be sustained, and we are obliged to reexamine our objection to instantaneous action-at-a-distance.

Why are physicists so squeamish about **superluminal influences**? After all, there are many things that travel faster than light. If a bug flies across the beam of a movie projector, the speed of its **shadow** is proportional to the distance to the screen; in principle, that distance can be as large as you like, and hence the shadow can move at arbitrarily high velocity (Figure 12.4). However, the shadow **does not carry any energy**; nor can it transmit a message from one point to another on the screen. A person at point $X$ cannot cause anything to happen at point $Y$ by manipulating the passing shadow.

On the other hand, a **causal influence** that propagated faster than light would carry unacceptable implications. For according to **special relativity** there exist inertial frames in which such a signal propagates **backward in time**—the effect preceding the cause—and this leads to inescapable logical anomalies. (You could, for example, arrange to kill your infant grandfather. Not a good idea!)  The question is, are the superluminal influences predicted by quantum mechanics and detected by 

$^9$ It is a curious twist of fate that the EPR paradox, which assumed locality in order to prove realism, led finally to the demise of locality and left the issue of realism undecided—the outcome (as Mermin put it) Einstein would have liked least. Most physicists today consider that if they can't have local realism, there's not much point in realism at all, and for this reason nonlocal hidden variable theories occupy a rather peripheral place. Still, some authors—notably Bell himself, in *Speakable and Unspeakable in Quantum Mechanics* (Cambridge University Press, 1987)—argue that such theories offer the best hope of bridging the conceptual gap between the measured system and the measuring apparatus, and for supplying an intelligible mechanism for the collapse of the wave function.

---

428 

Chapter 12 Afterword 

Aspect **causal**, in this sense, or are they somehow ethereal enough (like the motion of the shadow) to escape the philosophical objection? 

Well, let's consider Bell's experiment. Does the measurement of the electron **influence** the outcome of the positron measurement? **Assuredly it does**—otherwise we cannot account for the correlation of the data. But does the measurement of the electron **cause a particular outcome** for the positron? **Not in any ordinary sense of the word**. There is **no way** the person manning the electron detector could use his measurement to **send a signal** to the person at the positron detector, since he does not control the outcome of his own measurement (he cannot make a given electron come out spin up, any more than the person at $X$ can affect the passing shadow of the bug). It is true that he can decide whether to make a measurement at all, but the positron monitor, having immediate access only to data at his end of the line, **cannot tell whether the electron was measured or not**, for the lists of data compiled at the two ends, considered separately, are completely random. It is only when we compare the two lists later that we discover the remarkable **correlations**. In another reference frame the positron measurements occur before the electron measurements, and yet this leads to **no logical paradox**—the observed correlation is entirely symmetrical in its treatment, and it is a matter of indifference whether we say the observation of the electron influenced the measurement of the positron, or the other way around. This is a wonderfully delicate kind of influence whose only manifestation is a **subtle correlation** between two lists of otherwise random data.

We are led, then, to distinguish **two types of influence**:

1.  The "**causal**" variety, which produce actual changes in some physical property of the receiver, detectable by measurements on that subsystem alone.
2.  An "**ethereal**" kind, which **do not transmit energy or information**, and for which the only evidence is a **correlation** in the data taken on the two separate subsystems—a correlation which by its nature cannot be detected by examining either list alone.

Causal influences **cannot** propagate faster than light, but there is **no compelling reason** why ethereal ones should not. The influences associated with the collapse of the wave function are of the latter type, and the fact that they "travel" faster than light may be surprising, but it is not, after all, catastrophic.$^{10}$ 

## 12.3 THE NO-CLONE THEOREM 

Quantum measurements are typically **destructive**, in the sense that they **alter the state of the system measured**. This is how the uncertainty principle is enforced in the laboratory. You might wonder why we don't just make a bunch of identical copies (**clones**) of the original state, and measure them, leaving the system itself 

$^{10}$ An enormous amount has been written about Bell's theorem. My favorite is an inspired essay by David Mermin in *Physics Today* (April 1985, page 38). An extensive bibliography will be found in L. E. Ballentine, Am. J. Phys. 55, 785 (1987).

---

Section 12.3: The No-Clone Theorem 429 

...unscathed. **It can't be done.** Indeed, if you could build a cloning device (a "quantum Xerox machine"), **quantum mechanics would be out the window**.

For example, it would then be possible to send **superluminal messages** using the EPRB experiment. Say the message to be transmitted, from the operator of the positron detector to the operator of the electron detector, is either "**yes**" or "**no**".

* If the message is "**yes**," the sender measures $S_{z}$ (of the positron). Never mind what result she gets—all that matters is that she makes the measurement, for this means that the electron is now in the definite state $\uparrow$ or $\downarrow$ (never mind which). The receiver immediately makes a million clones of the electron, and measures $S_{z}$ on each of them. If they all yield the same answer (never mind which answer), we can be pretty sure that the electron was in fact measured, so the message is "**yes**".
* If half of them are spin up, and half spin down, then the electron was definitely not measured, and the message is "**no**".

But **you can't make a quantum Xerox machine**, as **Wootters, Zurek, and Dieks proved in 1982**.$^{11}$  Schematically, we want the machine to take as input a particle in state $|\psi\rangle$ (the one to be copied), plus a second particle in state $|X\rangle$ (the "blank sheet of paper"), and spit out two particles in the state $|\psi\rangle$ (original plus copy):
$$|\psi\rangle|X\rangle\rightarrow|\psi\rangle|\psi\rangle$$ 

Suppose we have made a device that successfully clones the state $|\psi_{1}\rangle$:
$$|\psi_{1}\rangle|X\rangle\rightarrow|\psi_{1}\rangle|\psi_{1}\rangle.$$ 
and also works for state $|\psi_{2}\rangle$:
$$|\psi_{2}\rangle|X\rangle\rightarrow|\psi_{2}\rangle|\psi_{2}\rangle$$ 
($|\psi_{1}\rangle$ and $|\psi_{2}\rangle$ might be spin up and spin down, for example, if the particle is an electron) . So far, so good. But what happens when we feed in a linear combination $|\psi\rangle=\alpha|\psi_{1}\rangle+\beta|\psi_{2}\rangle$? Evidently we get$^{12}$:
$$|\psi\rangle|X\rangle\rightarrow\alpha|\psi_{1}\rangle|\psi_{1}\rangle+\beta|\psi_{2}\rangle|\psi_{2}\rangle.$$ 

which is **not at all what we wanted**—what we wanted was:
$$|\psi\rangle|X\rangle\rightarrow|\psi\rangle|\psi\rangle=[\alpha|\psi_{1}\rangle+\beta|\psi_{2}\rangle][\alpha|\psi_{1}\rangle+\beta|\psi_{2}\rangle]$$ 
$$=\alpha^{2}|\psi_{1}\rangle|\psi_{1}\rangle+\beta^{2}|\psi_{2}\rangle|\psi_{2}\rangle+\alpha\beta[|\psi_{1}\rangle|\psi_{2}\rangle+|\psi_{2}\rangle|\psi_{1}\rangle].$$ 

$^{11}$ W. K. Wootters and W. H. Zurek, Nature 299, 802 (1982); D. Dieks, Phys. Lett. A 92, 271 (1982).

$^{12}$ This assumes that the device acts linearly on the state $|\Psi\rangle$, as it must, since the time-dependent Schrödinger equation (which presumably governs the process) is linear.

---

430 

Chapter 12 Afterword 

You can make a machine to clone spin-up electrons and spin-down electrons, but it's going to **fail for any nontrivial linear combinations**. It's as though you bought a Xerox machine that copies vertical lines perfectly, and also horizontal lines, but completely distorts diagonals.

## 12.4 SCHRÖDINGER'S CAT 

The **measurement process** plays a mischievous role in quantum mechanics: It is here that **indeterminacy, nonlocality, the collapse of the wave function, and all the attendant conceptual difficulties arise**. Absent measurement, the wave function evolves in a leisurely and deterministic way, according to the Schrödinger equation, and quantum mechanics looks like a rather ordinary field theory (much simpler than classical electrodynamics, for example, since there is only one field ($\Psi$), instead of two ($\mathbf{E}$ and $\mathbf{B}$), and it's a scalar). It is the bizarre role of the measurement process that gives quantum mechanics its extraordinary richness and subtlety. But **what, exactly, is a measurement?** What makes it so different from other physical processes?$^{13}$ And how can we tell when a measurement has occurred? 

**Schrödinger posed the essential question most starkly, in his famous cat paradox:**$^{14}$ 

> A cat is placed in a steel chamber, together with the following hellish contraption.... In a Geiger counter there is a tiny amount of radioactive substance, so tiny that maybe within an hour one of the atoms decays, but equally probably none of them decays. If one decays then the counter triggers and via a relay activates a little hammer which breaks a container of cyanide. If one has left this entire system for an hour, then one would say the cat is living if no atom has decayed. The first decay would have poisoned it. The wave function of the entire system would express this by containing equal parts of the living and dead cat.

At the end of the hour, the wave function of the cat has the schematic form:
$$\psi=\frac{1}{\sqrt{2}}(\psi_{alive}+\psi_{dead}).$$ 

$^{13}$ There is a school of thought that rejects this distinction, holding that the system and the measuring apparatus should be described by one great big wave function which itself evolves according to the Schrödinger equation. In such theories there is no collapse of the wave function , but one must typically abandon any hope of describing individual events—quantum mechanics (in this view) applies only to ensembles of identically prepared systems. See, for example, Philip Pearle Am. J. Phys. 35, 742 (1967), or Leslie E. Ballentine, *Quantum Mechanics: A Modern Development*, 2nd ed., World Scientific, Singapore (1998).

$^{14}$ E. Schrödinger, Naturwiss. 48, 52 (1935); translation by Josef M. Jauch, *Foundations of Quantum Mechanics*, Addison-Wesley, Reading (1968), p. 185.

---

Section 12.5: The Quantum Zeno Paradox 431 

The cat is neither alive nor dead, but rather a **linear combination of the two**, until a measurement occurs—until, say, you peek in the window to check. At that moment your observation forces the cat to "**take a stand**": dead or alive. And if you find him to be dead, then it's really you who killed him, by looking in the window.

Schrödinger regarded this as **patent nonsense**, and I think most physicists would agree with him. There is something **absurd** about the very idea of a macroscopic object being in a linear combination of two palpably different states. An electron can be in a linear combination of spin up and spin down, but a cat simply **cannot** be in a linear combination of alive and dead. How are we to reconcile this with the orthodox interpretation of quantum mechanics? 

The most widely accepted answer is that the **triggering of the Geiger counter constitutes the "measurement,"** in the sense of the statistical interpretation, **not the intervention of a human observer**. It is the essence of a measurement that some **macroscopic system is affected** (the Geiger counter, in this instance). The measurement occurs at the moment when the **microscopic system** (described by the laws of quantum mechanics) **interacts with the macroscopic system** (described by the laws of classical mechanics) in such a way as to **leave a permanent record**. The macroscopic system itself is not permitted to occupy a linear combination of distinct states.$^{15}$ 

I would not pretend that this is an entirely satisfactory resolution, but at least it avoids the stultifying solipsism of Wigner and others, who persuaded themselves that it is the **involvement of human consciousness that constitutes a measurement** in quantum mechanics. Part of the problem is the word "**measurement**" itself, which certainly carries a suggestion of human participation. Heisenberg proposed the word "**event**," which might be preferable. But I'm afraid "measurement" is so ingrained by now that we're stuck with it. And, in the end, no manipulation of the terminology can completely exorcise this mysterious ghost.

## 12.5 THE QUANTUM ZENO PARADOX 

The **collapse of the wave function** is undoubtedly the most peculiar feature of this whole bizarre story. It was introduced on purely theoretical grounds, to account for the fact that an immediately repeated measurement reproduces the same value. But surely such a radical postulate must carry directly observable consequences. In 

$^{15}$ Of course, in some ultimate sense the macroscopic system is itself described by the laws of quantum mechanics. But wave functions, in the first instance, describe individual elementary particles ; the wave function of a macroscopic object would be a monstrously complicated composite, built out of all the wave functions of its $10^{25}$ constituent particles. Presumably somewhere in the statistics of large numbers macroscopic linear combinations become extremely improbable. Indeed, if you were able somehow to get a damped pendulum (say) into a linear combination of macroscopically distinct quantum states, it would, in a tiny fraction of the damping time, revert to an ordinary classical state. This phenomenon is called **decoherence**. See, for example, R. Omnes, *The Interpretation of Quantum Mechanics* (Princeton, 1994), Chapter 7.

---

432 

Chapter 12 Afterword 

...1977 **Misra and Sudarshan**$^{16}$ proposed what they called the **quantum Zeno effect** as a dramatic experimental demonstration of the collapse of the wave function. Their idea was to take an unstable system (an atom in an excited state, say), and subject it to **repeated measurements**. Each observation collapses the wave function, resetting the clock, and it is possible by this means to **delay indefinitely the expected transition to the lower state**.$^{17}$ 

Specifically, suppose a system starts out in the excited state $\psi_{2}$, which has a natural lifetime $\tau$ for transition to the ground state $\psi_{1}$. Ordinarily, for times $t$ substantially less than $\tau$, the probability of a transition is proportional to $t$ (see Equation 9.42) ; in fact, since the transition rate is $1/\tau$:
$$P_{2\rightarrow1}=\frac{t}{\tau}$$ 

If we make a measurement after a time $t$, then, the probability that the system is still in the upper state is:
$$P_{2}(t)=1-\frac{t}{\tau}.$$ 

Suppose we do find it to be in the upper state. In that case the wave function collapses back to $\psi_{2}$ and the process starts all over again. If we make a second measurement, at $2t$, the probability that the system is still in the upper state is evidently:
$$\left(1-\frac{t}{\tau}\right)^{2}\approx1-\frac{2t}{\tau}.$$ 

which is the same as it would have been had we never made the first measurement at $t$. This is what one would naively expect; if it were the whole story there would be nothing gained by repeatedly observing the system, and there would be no quantum Zeno effect.

However, for **extremely short times**, the probability of a transition is not proportional to $t$, but rather to $t^{2}$ (see Equation 9.39):$^{18}$ 
$$P_{2\rightarrow1}=\alpha t^{2}.$$ 

In this case the probability that the system is still in the upper state after the two measurements is:
$$(1-\alpha t^{2})^{2}\approx1-2\alpha t^{2}$$ 

$^{16}$ B. Misra and E. C. G. Sudarshan, J. Math. Phys. 18, 756 (1977).

$^{17}$ This effect doesn't have much to do with Zeno, but it is reminiscent of the old adage, "a watched pot never boils," so it is sometimes called the **watched pot phenomenon**.

$^{18}$ In the argument leading to linear time dependence, we assumed that the function $\sin^2(\Omega t/2)/\Omega^2$ in Equation 9.39 was a sharp spike. However, the width of the "spike" is of order $\Delta\omega=4\pi/t$ , and for extremely short $t$ this approximation fails, and the integral becomes $(t^2/4)\int\rho(\omega)d\omega$.

---

Section 12.5: The Quantum Zeno Paradox 433 

...whereas if we had never made the first measurement it would have been:
$$1-\alpha(2t)^{2}\approx1-4\alpha t^{2}.$$ 

Evidently our observation of the system after time $t$ **decreased the net probability of a transition to the lower state**! 

Indeed, if we examine the system $n$ in regular intervals, from $t=0$ out to $t=T$ (that is, we make measurements at $T/n$, $2T/n$, $3T/n$, $\dots$, $T$), the probability that the system is still in the upper state at the end is:
$$\left(1-\alpha\left(\frac{T}{n}\right)^{2}\right)^{n}\approx1-\frac{\alpha}{n}T^{2}$$ 

which goes to **1 in the limit $n\rightarrow\infty$**: **A continuously observed unstable system never decays at all!** 

Some authors regard this as an absurd conclusion, and a proof that the collapse of the wave function is fallacious. However, their argument hinges on a rather loose interpretation of what constitutes "**observation**". If the track of a particle in a bubble chamber amounts to "continuous observation," then the case is closed, for such particles certainly do decay (in fact, their lifetime is not measurably extended by the presence of the detector). But such a particle is only intermittently interacting with the atoms in the chamber, and for the quantum Zeno effect to occur the successive measurements must be made **extremely rapidly**, in order to catch the system in the $t^{2}$ regime.

As it turns out, the experiment is impractical for spontaneous transitions, but it can be done using **induced transitions**, and the results are in **excellent agreement with the theoretical predictions**.$^{19}$  Unfortunately, this experiment is not as compelling a confirmation of the collapse of the wave function as its designers hoped; the observed effect can be accounted for in other ways.$^{20}$ 

*******

In this book I have tried to tell a consistent and coherent story:

* The wave function ($\Psi$) represents the state of a particle (or system).
* Particles do not in general possess specific dynamical properties (position, momentum, energy, angular momentum, etc.) until an **act of measurement intervenes**.
* The probability of getting a particular value in any given experiment is determined by the **statistical interpretation of $\Psi$**.
* Upon measurement the **wave function collapses**, so that an immediately repeated measurement is certain to yield the same result.

There are other possible interpretations—nonlocal hidden variable theories, the "**many worlds**" picture, "**consistent histories**," ensemble models, and others—but I believe this one 

$^{19}$ W. M. Itano, D. J. Heinzen, J. J. Bollinger, and D. J. Wineland, Phys. Rev. A 41, 2295 (1990).

$^{20}$ L. E. Ballentine, Found. Phys. 20, 1329 (1990); T. Petrosky, S. Tasaki, and I. Prigogine, Phys. Lett. A 151, 109 (1990).

---

434 

Chapter 12 Afterword 

...is **conceptually the simplest**, and certainly it is the one **shared by most physicists today**.$^{21}$  It has stood the test of time, and emerged unscathed from every experimental challenge. But I cannot believe this is the end of the story ; at the very least, we have much to learn about the nature of measurement and the mechanism of collapse. And it is entirely possible that future generations will look back, from the vantage point of a more sophisticated theory, and wonder how we could have been so gullible.

$^{21}$ See Daniel Styer et al., Am. J. Phys. 70, 288 (2002).
