---
title: "기술 통계량 및 주요 개념"
excerpt: "'확률과 통계' 과목의 9월 10일 강의 내용입니다."
tags: syllabus math statistics probability
header:
  teaser: https://drive.google.com/thumbnail?id=1jBqQiFKaiL3Jihts44p6JQ_3D9FGB4bR&sz=w1000
---

---

## Ross 챕터 2: 기술 통계량 및 주요 개념

강의는 주로 **기술 통계량(descriptive statistics)**의 정의와 그 활용, 그리고 데이터 분석의 핵심 개념인 **체비쇼프 부등식(Chebyshev's inequality)**과 **중심 극한 정리(Central Limit Theorem)**에 대해 다루고 있습니다.

### 1. 핵심 개념 및 용어 정의

*   **기술 통계량 (Descriptive Statistics)**
    *   **정의:** 데이터를 가장 잘 이해할 수 있는 방식으로 시각화하고 요약하여 제시하는 통계학의 한 분야입니다. 데이터의 특징을 명확하게 보여주는 것을 목표로 합니다.
    *   **예시:** 평균, 중앙값, 최빈값, 분산, 표준편차, 백분위수, 그리고 히스토그램이나 줄기-잎 그림과 같은 시각화 도구 등이 있습니다.

*   **표본 분산 (Sample Variance)**
    *   **정의:** 표본 데이터에서 계산되는 분산으로, 일반적으로 데이터 포인트 각각에서 표본 평균을 뺀 값들의 제곱을 합하여 $n$이 아닌 **$n-1$로 나누어 계산합니다**. 이 $n-1$은 표본 분산을 **불편 추정량(unbiased estimator)**으로 만들기 위한 것입니다.

*   **자유도 (Degrees of Freedom)**
    *   **정의:** 통계적 추정치를 계산할 때, 독립적으로 변할 수 있는 데이터 값의 개수를 의미합니다. 표본 분산을 계산할 때 표본 평균($\bar{X}$)이 이미 추정 과정에 사용되어 하나의 자유도가 소실되기 때문에 $n-1$로 나누게 됩니다.

*   **불편 추정량 (Unbiased Estimator)**
    *   **정의:** 추정량의 기대값($E[\text{추정량}]$)이 추정하려는 실제 모수의 값과 동일한 경우를 말합니다. 표본 분산을 $n-1$로 나누는 것은 이를 불편 추정량으로 만들기 위함입니다.

*   **모수 추정량 (Parameter Estimator) / 추정 (Estimation)**
    *   **정의:** 모집단의 알려지지 않은 모수(예: 평균, 분산)의 값을 표본 데이터를 사용하여 예측하는 과정입니다. 이 예측을 수행하는 통계량을 **추정량(estimator)**이라 하고, 이 과정을 **추정(estimation)**이라고 합니다.

*   **백분위수 (Percentile)**
    *   **정의:** 전체 데이터 분포에서 특정 비율($p$)의 데이터가 그 값보다 작거나 같은 값을 의미합니다. 예를 들어, 90번째 백분위수(P90)는 전체 데이터의 90%가 그 값보다 작거나 같다는 뜻입니다. 고등학교 성적 등에서 흔히 사용되는 개념입니다. 이는 또한 100 * (1-p) 퍼센트의 데이터가 그 값보다 크거나 같다는 것을 의미합니다. 한국어 "백분위"라는 용어와 혼동될 수 있음을 언급합니다.

*   **정규 분포 (Normal Distribution)**
    *   **정의:** 통계학에서 가장 흔하게 사용되는 연속 확률 분포 중 하나로, 종(bell) 모양의 대칭적인 곡선 형태를 가집니다. 많은 자연 현상에서 데이터가 근사적으로 정규 분포를 따르며, SAT, ACT, GRE, LSET와 같은 표준화 시험 점수를 설명하는 데 유용합니다.

*   **경험적 규칙 (Empirical Rule)**
    *   **정의:** 데이터가 정규 분포를 따른다는 가정하에, 평균으로부터 1, 2, 3 표준편차 이내에 데이터의 특정 비율이 포함된다는 규칙입니다. 이는 체비쇼프 부등식보다 "더 타이트한(tighter)" 예측을 제공합니다.

### 2. 법칙 및 정리의 공식적인 표현과 그 의미

*   **체비쇼프 부등식 (Chebyshev's Inequality)**
    *   **공식적인 표현:** 데이터가 평균($\mu$)으로부터 $k$배의 표준편차($\sigma$) 이상 떨어져 있을 확률에 대한 상한을 나타냅니다.
        $$P(|X - \mu| \ge k\sigma) \le \frac{1}{k^2}$$
        여기서 $N_{sk}$는 집합 $s_k$에 있는 원소의 개수, $N$은 전체 원소의 개수라고 할 때, $N_{sk}/N$의 비율이 $1/k^2$보다 작거나 같음을 나타냅니다.
    *   **의미:** 이 부등식은 특정 분포 형태를 가정하지 않고도, 데이터가 평균으로부터 $k$ 표준편차 이상 떨어져 있을 확률의 상한을 $1/k^2$로 제한합니다. 즉, 데이터가 평균 주변에 얼마나 집중되어 있는지를 나타내는 **최소한의 비율(하한)**을 제공합니다. 이는 분포에 대한 정보가 거의 없을 때도 적용할 수 있는 매우 일반적인("원시적인", primitive) 결과입니다.

*   **중심 극한 정리 (Central Limit Theorem, CLT)**
    *   **공식적인 표현:** (소스에 명확한 수학적 공식은 없지만, 의미는 설명됩니다.)
    *   **의미:** 모집단의 분포가 무엇이든 관계없이, 표본의 크기($n$)가 충분히 커지면 표본 평균의 분포가 정규 분포에 가까워진다는 것을 수학적으로 보장합니다. 이 정리는 여러 번 반복된 실험 데이터를 누적할 때 데이터 분포가 정규 분포 형태를 띠게 되는 현상을 설명합니다.

### 3. 다양한 법칙이나 개념들의 연결성

*   **표본 분산의 'n-1'과 자유도 및 불편 추정량:**
    *   표본 분산을 계산할 때 $n$ 대신 $n-1$로 나누는 것은 그 추정량을 **불편 추정량**으로 만들기 위함입니다. 이는 표본 평균($\bar{X}$)을 사용하여 편차를 계산할 때 데이터 내에 존재하는 하나의 **자유도**를 소모하기 때문입니다.

*   **중심 극한 정리와 정규 분포:**
    *   중심 극한 정리는 **정규 분포**의 광범위한 적용 가능성을 설명합니다. 이 정리는 표본 크기가 충분히 크다면 모집단 분포에 관계없이 표본 평균의 분포가 정규 분포에 가까워지므로, 정규 분포가 많은 통계적 추론 방법의 기반이 되는 이유를 제공합니다.

*   **체비쇼프 부등식, 경험적 규칙, 정규 분포:**
    *   **체비쇼프 부등식**은 어떤 확률 분포에서든 데이터가 평균으로부터 특정 거리 이내에 있을 확률에 대한 **일반적인 하한(느슨한 범위)**을 제공합니다. 이는 분포의 형태를 모를 때도 유용합니다.
    *   반면 **경험적 규칙**은 데이터가 **정규 분포**를 따른다는 **특정 가정**하에, 평균으로부터 표준편차 이내에 포함되는 데이터의 비율을 더 정확하게 제시합니다. 즉, 정규 분포라는 추가적인 정보를 사용하면 체비쇼프 부등식보다 훨씬 "타이트한(tighter)" 추정치를 얻을 수 있습니다. 체비쇼프 부등식은 모든 분포에 적용 가능한 "원시적인(primitive)" 방법이고, 경험적 규칙은 정규 분포에 특화된 개선된 정보로 볼 수 있습니다.

### 4. 한 개념이 다른 개념의 유도나 이해에 기여하는 방식

*   **자유도 개념의 기여:** **자유도** 개념은 표본 분산 공식에서 $n-1$을 사용하는 이유를 설명하는 데 결정적으로 기여합니다. 표본 평균을 추정하기 위해 한 자유도를 사용했기 때문에, 남은 $n-1$개의 자유도만이 분산 추정에 사용되어야 **불편 추정량**이 될 수 있습니다.

*   **중심 극한 정리의 기여:** **중심 극한 정리**는 표본 평균의 분포가 정규 분포에 근사한다는 것을 보여줌으로써, 통계학에서 정규 분포의 중요성을 크게 높입니다. 이는 다양한 표준화 시험 점수(SAT, ACT, GRE)가 정규 분포를 따르는 경향이 있는 이유를 설명하는 데 기여합니다.

### 5. 특정 법칙이나 공식이 유효하게 적용되는 조건이나 가정

*   **표본 분산 ($S^2$):**
    *   **조건:** 표본은 모집단에서 추출된 독립적이고 동일하게 분포된(i.i.d.) 표본이어야 합니다. 모집단 평균을 알지 못하고 표본 평균을 사용해야 합니다.
    *   **가정:** 관측치들이 독립적이어야 합니다.

*   **체비쇼프 부등식:**
    *   **조건:** 확률 변수 $X$가 유한한 기대값($\mu$)과 유한한 분산($\sigma^2$)을 가져야 합니다.
    *   **가정:** 분포의 형태에 대한 추가적인 가정은 필요 없습니다. 모든 종류의 데이터셋에 적용 가능합니다.

*   **중심 극한 정리:**
    *   **조건:** 표본들이 독립적이고 동일하게 분포된(i.i.d.) 확률 변수여야 하며, 각 확률 변수의 분산이 유한해야 합니다.
    *   **가정:** **표본 크기($n$)가 충분히 커야 합니다.** 모집단의 분포 형태는 무엇이든 상관없습니다.

*   **경험적 규칙:**
    *   **조건:** 데이터가 **정규 분포**를 따른다는 가정이 필수적입니다.

### 6. 체비쇼프 부등식의 유도 과정 (증명 스케치)

체비쇼프 부등식의 유도 과정은 분산의 정의를 바탕으로 이루어집니다.

1.  **분산의 정의:**
    확률 변수 $X$의 분산 $\sigma^2$은 다음과 같이 정의됩니다:
    $$\sigma^2 = E[(X - \mu)^2]$$
    이를 이산 확률 변수에 대한 합으로 표현하면:
    $$\sigma^2 = \sum (x_i - \mu)^2 P(X=x_i)$$

2.  **영역 분할:**
    위 합을 두 부분으로 나눕니다: $|x_i - \mu| \ge k\sigma$인 부분(집합 $s_k$)과 $|x_i - \mu| < k\sigma$인 부분.

3.  **부등식 적용:**
    $|x_i - \mu| < k\sigma$인 부분은 무시하고, $|x_i - \mu| \ge k\sigma$인 부분에 대해서만 합을 취하면 원래 $\sigma^2$보다 작거나 같은 값을 얻습니다. 이 과정에서 항들을 더 작은 값으로 대체하여 부등식을 형성합니다.
    $$\sigma^2 \ge \sum_{|x_i - \mu| \ge k\sigma} (x_i - \mu)^2 P(X=x_i)$$
    이 영역에서는 $(x_i - \mu)^2 \ge (k\sigma)^2 = k^2 \sigma^2$이므로, 각 항을 $k^2 \sigma^2$으로 치환하면 부등식은 더욱 강해집니다:
    $$\sigma^2 \ge \sum_{|x_i - \mu| \ge k\sigma} k^2 \sigma^2 P(X=x_i)$$

4.  **$k^2 \sigma^2$ 밖으로 빼내기:**
    $$\sigma^2 \ge k^2 \sigma^2 \sum_{|x_i - \mu| \ge k\sigma} P(X=x_i)$$
    여기서 $\sum_{|x_i - \mu| \ge k\sigma} P(X=x_i)$는 바로 $P(|X - \mu| \ge k\sigma)$입니다.

5.  **최종 부등식:**
    따라서 다음이 성립합니다:
    $$\sigma^2 \ge k^2 \sigma^2 P(|X - \mu| \ge k\sigma)$$
    양변을 $k^2 \sigma^2$으로 나누면 (단, $k>0, \sigma^2>0$):
    $$P(|X - \mu| \ge k\sigma) \le \frac{1}{k^2}$$
    이것이 체비쇼프 부등식입니다.

### 7. 특정 현상이나 결론에 대한 물리적 또는 수학적 근거

*   **표본 분산의 $n-1$ 사용:**
    *   **수학적 근거 (자유도 손실):** 표본 평균($\bar{X}$)은 $n$개의 데이터 포인트로 계산됩니다. 이 $\bar{X}$를 사용하여 각 데이터 포인트 $X_i$의 편차 $X_i - \bar{X}$를 계산할 때, 이 편차들의 합 $\sum (X_i - \bar{X})$은 항상 0이 됩니다. 이는 $n$개의 편차 중 $n-1$개만 독립적으로 변할 수 있음을 의미하며, 마지막 편차는 다른 $n-1$개에 의해 결정되므로 하나의 자유도가 소실됩니다. 따라서 편향되지 않은(unbiased) 분산 추정량을 얻기 위해서는 $n-1$로 나누는 것이 수학적으로 정확합니다.

*   **정규 분포의 보편성 및 표준화 시험에서의 활용:**
    *   **수학적 근거 (중심 극한 정리):** SAT, ACT, GRE와 같은 많은 표준화 시험 점수 분포가 정규 분포를 따르는 경향이 있는 것은 **중심 극한 정리** 때문입니다. 여러 독립적인 작은 요인들이 무작위로 작용하여 최종 결과를 형성할 때, 그 결과의 분포는 정규 분포에 가까워지는 경향이 있습니다. 시험 점수는 응시자의 학습 능력, 시험 운, 컨디션 등 다양한 요인의 합산으로 볼 수 있으며, 이들이 독립적으로 작용하여 전체 점수 분포가 정규 분포와 유사하게 나타나는 것입니다.

*   **체비쇼프 부등식의 "원시적인" 특성:**
    *   **수학적 근거 (일반성):** 체비쇼프 부등식은 분포의 형태에 대한 어떠한 가정도 필요 없기 때문에 매우 일반적인 상황에 적용될 수 있습니다. 그러나 이 일반성 때문에, 정규 분포와 같은 특정 분포에 대해서는 **경험적 규칙**처럼 더 정확하고 "타이트한" 예측을 제공하지 못합니다. 이는 유도 과정에서 부등식을 만들기 위해 일부 정보를 제거하거나 하한으로 대체하는 "느슨한" 근사를 사용했기 때문입니다.

---

**아날로지 또는 메타포:**

체비쇼프 부등식은 마치 낯선 도시를 여행할 때 "최소한 이만큼의 사람들은 도심에서 이 정도 거리에 있을 것이다"라고 예측하는 것과 같습니다. 당신은 도시의 지도를 전혀 모르지만, 기본적인 인구 정보와 도시의 넓이에 대한 대략적인 정보를 가지고 대략적인 추측을 하는 것입니다. 이 예측은 매우 일반적이어서 어떤 도시에도 적용할 수 있지만, 특정 도시(예: 정규 분포를 따르는 도시)에 대한 추가 정보를 알게 되면 훨씬 더 정확하고 구체적인 예측(예: 경험적 규칙)을 할 수 있게 됩니다.